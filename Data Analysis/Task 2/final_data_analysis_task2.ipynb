{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MaSaC_train_efr.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Shubham\\B-Tech\\Study\\Academics\\Semester_5\\CS779\\Practical\\Project\\Import-NLP-SemEval-2024-Task-10\\Data Analysis\\Task 2\\final_data_analysis_task2.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Shubham/B-Tech/Study/Academics/Semester_5/CS779/Practical/Project/Import-NLP-SemEval-2024-Task-10/Data%20Analysis/Task%202/final_data_analysis_task2.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Read File\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Shubham/B-Tech/Study/Academics/Semester_5/CS779/Practical/Project/Import-NLP-SemEval-2024-Task-10/Data%20Analysis/Task%202/final_data_analysis_task2.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMaSaC_train_efr.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Shubham/B-Tech/Study/Academics/Semester_5/CS779/Practical/Project/Import-NLP-SemEval-2024-Task-10/Data%20Analysis/Task%202/final_data_analysis_task2.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_name, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Shubham/B-Tech/Study/Academics/Semester_5/CS779/Practical/Project/Import-NLP-SemEval-2024-Task-10/Data%20Analysis/Task%202/final_data_analysis_task2.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(file)\n",
      "File \u001b[1;32mc:\\Shubham\\B-Tech\\Study\\Academics\\Semester_5\\CS779\\Practical\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MaSaC_train_efr.json'"
     ]
    }
   ],
   "source": [
    "# Read File\n",
    "\n",
    "file_name = \"MaSaC_train_efr.json\"\n",
    "with open(file_name, 'r') as file:\n",
    "        dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of episodes in dataset\n",
    "\n",
    "N = len(dataset)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Episode\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Flip Analysis\n",
    "\n",
    "# Read File\n",
    "\n",
    "file_name = \"MaSaC_train_efr.json\"\n",
    "with open(file_name, 'r') as file:\n",
    "        dataset = json.load(file)\n",
    "\n",
    "# Reading the data\n",
    "\n",
    "episodes_list = []\n",
    "speakers_list = []\n",
    "utterances_list = []\n",
    "triggers_list = []\n",
    "emotions_list = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "        episodes_list.append(dataset[i]['episode'])\n",
    "        speakers_list.append(dataset[i]['speakers'])\n",
    "        utterances_list.append(dataset[i]['utterances'])\n",
    "        triggers_list.append(dataset[i]['triggers'])\n",
    "        emotions_list.append(dataset[i]['emotions'])  \n",
    "\n",
    "N = len(dataset)   \n",
    "\n",
    "data = [[],[],[],[],[]]\n",
    "# prev_first_sen = utterances_list[0][0]\n",
    "d_id = -1\n",
    "for i in range(N):\n",
    "    if i==N-1 or utterances_list[i][0]!=utterances_list[i+1][0]:\n",
    "        d_id+=1\n",
    "        # if i!=N-1:\n",
    "        #         prev_first_sen = utterances_list[i+1][0]\n",
    "        data_temp = [[],[],[],[],[]]\n",
    "        \n",
    "        for j in range(len(utterances_list[i])):\n",
    "            data_temp[0].append(d_id)\n",
    "            data_temp[1].append(speakers_list[i][j])\n",
    "            data_temp[2].append(emotions_list[i][j])\n",
    "            data_temp[3].append(utterances_list[i][j])\n",
    "            data_temp[4].append(triggers_list[i][j])\n",
    "        \n",
    "        data[0].append(data_temp[0])\n",
    "        data[1].append(data_temp[1])\n",
    "        data[2].append(data_temp[2])\n",
    "        data[3].append(data_temp[3])\n",
    "        data[4].append(data_temp[4])\n",
    "                       \n",
    "speakers_list_uq = data[1]\n",
    "emotions_list_uq = data[2]\n",
    "utterances_list_uq = data[3]\n",
    "triggers_list_uq = data[4]\n",
    "\n",
    "N_uq = len(utterances_list_uq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N)\n",
    "print(N_uq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker Data Analysis\n",
    "\n",
    "# Data Processing\n",
    "speakers_data_uq = [None] * N_uq\n",
    "\n",
    "for i in range(N_uq):\n",
    "    c_uq = Counter()\n",
    "    c_uq.update(speakers_list_uq[i])\n",
    "    speakers_data_uq[i] = c_uq.items()\n",
    "\n",
    "# Finding Average\n",
    "instance_count_uq = 0\n",
    "total_count_uq = 0\n",
    "for i in range(N_uq):\n",
    "    for person, utt_count in speakers_data_uq[i]:\n",
    "        total_count_uq += utt_count\n",
    "        instance_count_uq += 1\n",
    "\n",
    "print(\"Total Utterances \", total_count_uq)\n",
    "avg_utt_per_person_uq = total_count_uq / instance_count_uq\n",
    "print(\"Average Number of Utterances one person performs in an episode is {:.2f}\".format( avg_utt_per_person_uq))\n",
    "\n",
    "# Speaker Count Data Analysis\n",
    "person_count_uq = 0\n",
    "for i in range(N_uq):\n",
    "    for person, utt_count in speakers_data_uq[i]:\n",
    "        person_count_uq += 1\n",
    "        \n",
    "print(\"Average Number of Speakers in an episode is {:.2f}\".format(person_count_uq / N_uq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count_uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterance Count Data Analysis\n",
    "utterances_count_uq = [None] * N_uq\n",
    "\n",
    "for i in range(N_uq):\n",
    "    utterances_count_uq[i] = len(utterances_list_uq[i])\n",
    "   \n",
    "total_count_uq = 0\n",
    "for i in range(N_uq):\n",
    "    total_count_uq += utterances_count_uq[i]\n",
    "    \n",
    "print(\"Average Number of Utterances in an episode is {:.2f}\".format(total_count_uq / N_uq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger Count Data Analysis\n",
    "triggers_count = [None] * N\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(len(triggers_list[i])):\n",
    "        try:\n",
    "            triggers_list[i][j] = int(float(triggers_list[i][j]))\n",
    "        except:\n",
    "            print(f\"Data Error: In episode {i} the utterance {j} has trigger label {triggers_list[i][j]}\")  \n",
    "            triggers_list[i][j] = 0\n",
    "            \n",
    "    triggers_count[i] = sum(triggers_list[i])\n",
    "   \n",
    "total_count = 0\n",
    "for i in range(N):\n",
    "    total_count += triggers_count[i]\n",
    "    \n",
    "print(\"Average Number of triggers in an episode is {:.2f}\".format(total_count / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Count Data Analysis\n",
    "emotions_data_uq = [None] * N_uq\n",
    "\n",
    "for i in range(N_uq):\n",
    "    c_uq = Counter()\n",
    "    c_uq.update(emotions_list_uq[i])\n",
    "    emotions_data_uq[i] = c_uq.items()\n",
    "    \n",
    "c_uq = Counter()\n",
    "for i in range(N_uq):\n",
    "    c_uq.update(emotions_list_uq[i])\n",
    "\n",
    "for count, label in sorted( ((v,k) for k,v in c_uq.items()), reverse=True):\n",
    "    print(f\"Utterances with label {label} is {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger Detailed Analysis\n",
    "\n",
    "labels = [\"neutral\", \"anger\", \"surprise\", \"fear\", \"joy\", \"sadness\", \"disgust\", \"contempt\"]\n",
    "\n",
    "count_dict = {}\n",
    "for l in labels:\n",
    "    count_dict[l] = 0\n",
    "\n",
    "dist_counter = Counter()\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(len(triggers_list[i])):\n",
    "        if triggers_list[i][j]==1:\n",
    "            to_emotion = emotions_list[i][j]\n",
    "            count_dict[to_emotion] += 1\n",
    "            dist_counter.update([len(triggers_list[i])-1 - j])\n",
    "            \n",
    "for count, label in sorted( ((v,k) for k,v in count_dict.items()), reverse=True):\n",
    "    print(f\"Number of Triggers which had emotion {label} are {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_label = pd.DataFrame(columns=['emotion', 'count'], data=count_dict.items())\n",
    "utt_label = utt_label.rename(columns={'emotion': 'Emotion', 'count': 'Utterance count'})\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme('paper')\n",
    "sns.catplot(data=utt_label.sort_values(by='Utterance count', ascending=False), kind='bar', y='Emotion', x='Utterance count')\\\n",
    "    .set(title='Emotion counts')\n",
    "plt.savefig('task2_emotion_counts.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_counter\n",
    "\n",
    "x = dict(dist_counter)\n",
    "\n",
    "import numpy as np\n",
    "labels, values = zip(*dist_counter.items())\n",
    "labels = np.array(labels)\n",
    "values = np.array(values)\n",
    "ind = np.argsort(labels)\n",
    "labels = labels[ind]\n",
    "values = values[ind]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indexes = np.arange(len(labels[:10]))\n",
    "width = 1\n",
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n",
    "plt.bar(indexes[:10], values[:10], width)\n",
    "plt.xticks(indexes)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Distance\")\n",
    "# plt.show()\n",
    "plt.savefig('MaSaC_dist_stats.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"neutral\", \"anger\", \"surprise\", \"fear\", \"joy\", \"sadness\", \"disgust\", \"contempt\"]\n",
    "\n",
    "# Defining the variables\n",
    "is_flip = [None] * N_uq\n",
    "flip_from_emotion = [None] * N_uq\n",
    "flip_from_index = [None] * N_uq\n",
    "flip_to_emotion = [None] * N_uq\n",
    "flip_to_index = [None] * N_uq\n",
    "for i in range(N_uq):\n",
    "    k = len(utterances_list_uq[i])\n",
    "    is_flip[i] = [0] * k\n",
    "    flip_from_emotion[i] = [None] * k\n",
    "    flip_from_index[i] = [None] * k\n",
    "    flip_to_emotion[i] = [None] * k\n",
    "    flip_to_index[i] = [None] * k\n",
    "\n",
    "# Filling the variables\n",
    "for i in range(N_uq):\n",
    "    speakers = set(speakers_list_uq[i])\n",
    "    state_dict = {}\n",
    "    for sp in speakers:\n",
    "        state_dict[sp] = (None, None)   # (ix, emotion)\n",
    "    \n",
    "    for j in range(len(utterances_list_uq[i])):\n",
    "        sp = speakers_list_uq[i][j]\n",
    "        sp_emotion = emotions_list_uq[i][j]\n",
    "        if state_dict[sp][0]==None:\n",
    "            state_dict[sp] = (j, sp_emotion)\n",
    "        else:\n",
    "            if state_dict[sp][1]!=sp_emotion:\n",
    "                is_flip[i][j] = 1\n",
    "                flip_from_emotion[i][j] = state_dict[sp][1]\n",
    "                flip_from_index[i][j] = state_dict[sp][0]\n",
    "                flip_to_emotion[i][j] = sp_emotion\n",
    "                flip_to_index[i][j] = j\n",
    "            \n",
    "            state_dict[sp] = (j, sp_emotion)          \n",
    "            \n",
    "# Data Analysis\n",
    "flip_pair_dict = {}\n",
    "for label1 in labels:\n",
    "    for label2 in labels:\n",
    "        flip_pair_dict[(label1, label2)] = [0, 0]\n",
    "       \n",
    "dist_counter= Counter()\n",
    "for i in range(N_uq):\n",
    "    for j in range(len(utterances_list_uq[i])):\n",
    "        if is_flip[i][j]==1:\n",
    "            flip_pair_dict[(flip_from_emotion[i][j], flip_to_emotion[i][j])][0] += 1\n",
    "            flip_pair_dict[(flip_from_emotion[i][j], flip_to_emotion[i][j])][1] += flip_to_index[i][j] - flip_from_index[i][j]\n",
    "            dist_counter.update([flip_to_index[i][j] - flip_from_index[i][j]])\n",
    "\n",
    "# Formatting\n",
    "from decimal import Decimal, getcontext\n",
    "getcontext().prec = 3\n",
    "\n",
    "# Displaying Results\n",
    "count_result = {}\n",
    "for label1 in labels:\n",
    "    count_result[label1] = [0] * len(labels)\n",
    "\n",
    "for i, label1 in enumerate(labels):\n",
    "    for j, label2 in enumerate(labels):\n",
    "        count_result[label1][j] = flip_pair_dict[(label1, label2)][0]\n",
    "        \n",
    "dist_result = {}\n",
    "\n",
    "for label1 in labels:\n",
    "    dist_result[label1] = [0] * len(labels)\n",
    "\n",
    "for i, label1 in enumerate(labels):\n",
    "    for j, label2 in enumerate(labels):\n",
    "        if flip_pair_dict[(label1, label2)][0]!=0:\n",
    "            dist_result[label1][j] = Decimal(flip_pair_dict[(label1, label2)][1]) / Decimal(flip_pair_dict[(label1, label2)][0])\n",
    "        else:\n",
    "            dist_result[label1][j] = 0\n",
    "\n",
    "print(\"Count Statistics\")       \n",
    "print(\"Row Labels are emotion FLIP FROM EMOTION and Column Labels are FLIP TO EMOTION\")\n",
    "df_count = pd.DataFrame(count_result, pd.Index(labels))\n",
    "print(df_count)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Distance between utterances of the flip\")\n",
    "print(\"Row Labels are emotion FLIP FROM EMOTION and Column Labels are FLIP TO EMOTION\")\n",
    "df_dist = pd.DataFrame(dist_result, pd.Index(labels))\n",
    "print(df_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax = sns.heatmap(df_count, annot=True, fmt='.0f', cmap='Blues', square=True)\n",
    "ax.set_title('Flip Count Statistics')\n",
    "ax.set_xlabel('From Emotion')\n",
    "ax.set_ylabel('To Emotion')\n",
    "plt.savefig('task2_flip_count_stats.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
